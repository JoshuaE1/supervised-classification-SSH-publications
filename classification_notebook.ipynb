{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Data cleaning and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from mlutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to true to save intermediate files\n",
    "SAVE_INTERMEDIATE_FILES = False\n",
    "# Random seed\n",
    "RANDOM_SEED = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Title</th>\n",
       "      <th>StoreId</th>\n",
       "      <th>disc2_x</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The initiation, development, and disseminati...</td>\n",
       "      <td>Development and Dissemination of Collaborative...</td>\n",
       "      <td>1001404248</td>\n",
       "      <td>['050408']</td>\n",
       "      <td>The initiation, development, and disseminati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>As the population of the United States has cha...</td>\n",
       "      <td>Conducting Culturally Competent Evaluations of...</td>\n",
       "      <td>1010629836</td>\n",
       "      <td>['050409']</td>\n",
       "      <td>As the population of the United States has cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In the social sciences, evaluation sometimes a...</td>\n",
       "      <td>Evaluation, research and demonstration in the ...</td>\n",
       "      <td>1010629842</td>\n",
       "      <td>['050411']</td>\n",
       "      <td>In the social sciences, evaluation sometimes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Second Earth Summit to be held in Rio de J...</td>\n",
       "      <td>Entering the anthropocene: 'Geonauts' or sorce...</td>\n",
       "      <td>1010629881</td>\n",
       "      <td>['050404']</td>\n",
       "      <td>The Second Earth Summit to be held in Rio de J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This article investigates the matrimonial web ...</td>\n",
       "      <td>The matrimonial web of migrants: The economics...</td>\n",
       "      <td>1010629926</td>\n",
       "      <td>['050401']</td>\n",
       "      <td>This article investigates the matrimonial web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113904</th>\n",
       "      <td>58024</td>\n",
       "      <td>As punitive damages have gained greater visibi...</td>\n",
       "      <td>Reconciling Punitive Damages with Tort Law's N...</td>\n",
       "      <td>963637137</td>\n",
       "      <td>['050201']</td>\n",
       "      <td>As punitive damages have gained greater visibi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113905</th>\n",
       "      <td>58025</td>\n",
       "      <td>The worldwide financial crisis and the need to...</td>\n",
       "      <td>Theory for an Age of Crisis: Seeing Money as a...</td>\n",
       "      <td>963637138</td>\n",
       "      <td>['050205']</td>\n",
       "      <td>The worldwide financial crisis and the need to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113906</th>\n",
       "      <td>58026</td>\n",
       "      <td>In this paper, I review the literature on the ...</td>\n",
       "      <td>The Econometrics of DSGE Models</td>\n",
       "      <td>963637157</td>\n",
       "      <td>['050205']</td>\n",
       "      <td>In this paper, I review the literature on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113907</th>\n",
       "      <td>58027</td>\n",
       "      <td>Bayesian dynamic stochastic general equilibriu...</td>\n",
       "      <td>DSGE Models and Their Use at the ECB</td>\n",
       "      <td>963637159</td>\n",
       "      <td>['050205']</td>\n",
       "      <td>Bayesian dynamic stochastic general equilibriu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113908</th>\n",
       "      <td>58028</td>\n",
       "      <td>Corporate social responsibility is a concept t...</td>\n",
       "      <td>Consumers' Perceptions towards Corporate Socia...</td>\n",
       "      <td>963637199</td>\n",
       "      <td>['050206']</td>\n",
       "      <td>Corporate social responsibility is a concept t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113909 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           Abstract  \\\n",
       "0                0    The initiation, development, and disseminati...   \n",
       "1                1  As the population of the United States has cha...   \n",
       "2                2  In the social sciences, evaluation sometimes a...   \n",
       "3                3  The Second Earth Summit to be held in Rio de J...   \n",
       "4                4  This article investigates the matrimonial web ...   \n",
       "...            ...                                                ...   \n",
       "113904       58024  As punitive damages have gained greater visibi...   \n",
       "113905       58025  The worldwide financial crisis and the need to...   \n",
       "113906       58026  In this paper, I review the literature on the ...   \n",
       "113907       58027  Bayesian dynamic stochastic general equilibriu...   \n",
       "113908       58028  Corporate social responsibility is a concept t...   \n",
       "\n",
       "                                                    Title     StoreId  \\\n",
       "0       Development and Dissemination of Collaborative...  1001404248   \n",
       "1       Conducting Culturally Competent Evaluations of...  1010629836   \n",
       "2       Evaluation, research and demonstration in the ...  1010629842   \n",
       "3       Entering the anthropocene: 'Geonauts' or sorce...  1010629881   \n",
       "4       The matrimonial web of migrants: The economics...  1010629926   \n",
       "...                                                   ...         ...   \n",
       "113904  Reconciling Punitive Damages with Tort Law's N...   963637137   \n",
       "113905  Theory for an Age of Crisis: Seeing Money as a...   963637138   \n",
       "113906                    The Econometrics of DSGE Models   963637157   \n",
       "113907               DSGE Models and Their Use at the ECB   963637159   \n",
       "113908  Consumers' Perceptions towards Corporate Socia...   963637199   \n",
       "\n",
       "           disc2_x                                               text  \n",
       "0       ['050408']    The initiation, development, and disseminati...  \n",
       "1       ['050409']  As the population of the United States has cha...  \n",
       "2       ['050411']  In the social sciences, evaluation sometimes a...  \n",
       "3       ['050404']  The Second Earth Summit to be held in Rio de J...  \n",
       "4       ['050401']  This article investigates the matrimonial web ...  \n",
       "...            ...                                                ...  \n",
       "113904  ['050201']  As punitive damages have gained greater visibi...  \n",
       "113905  ['050205']  The worldwide financial crisis and the need to...  \n",
       "113906  ['050205']  In this paper, I review the literature on the ...  \n",
       "113907  ['050205']  Bayesian dynamic stochastic general equilibriu...  \n",
       "113908  ['050206']  Corporate social responsibility is a concept t...  \n",
       "\n",
       "[113909 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'Abstract': str,\n",
    "    'Title': str,\n",
    "    'year': int,\n",
    "    'documentType': str,\n",
    "    'StoreId': str,\n",
    "    'disc1': str,\n",
    "    'disc2': str,\n",
    "}\n",
    "\n",
    "socab_df = pd.read_csv('Datasets/SocAbstracts.csv', dtype=dtypes)\n",
    "eric_df = pd.read_csv('Datasets/ERIC.csv', dtype=dtypes)\n",
    "econlit_df = pd.read_csv('Datasets/EconLit.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data cleaning and relabeling\n",
    "\n",
    "Get clean and relabeled dataframes for each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "socab_clean = clean_df(socab_df)\n",
    "eric_clean = clean_df(eric_df)\n",
    "econlit_clean = clean_df(econlit_df)\n",
    "\n",
    "if SAVE_INTERMEDIATE_FILES:\n",
    "    socab_clean.to_csv(\"SocAbstracts_master.csv\", index=False)\n",
    "    eric_clean.to_csv(\"ERIC_master.csv\", index=False)\n",
    "    econlit_clean.to_csv(\"EconLit_master.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abstract', 'Title', 'year', 'StoreId', 'disc1_x', 'disc2_x',\n",
       "       'disc1_counts', 'disc2_counts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which columns are stored?\n",
    "socab_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Here, we skip some unneeded parts from the full notebook..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([socab_clean,eric_clean,econlit_clean])\n",
    "df = df.drop(columns=['year', 'disc1_x', 'disc1_counts', 'disc2_counts'])\n",
    "\n",
    "if SAVE_INTERMEDIATE_FILES:\n",
    "    # Transform list to semicolon-separated string prior to saving\n",
    "    df['disc2_x'] = df.disc2_x.apply(lambda x: ';'.join(x))\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    # Read file and transform back to list format\n",
    "    df = pd.read_csv(\"dataset.csv\")\n",
    "    df['disc2_x'] = df.disc2_x.str.split(';')\n",
    "\n",
    "df.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.Abstract.str.cat(df.Title, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe with all correct labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_true = mlb.fit_transform(df['disc2_x'])\n",
    "labels = list(mlb.classes_)\n",
    "df_true = pd.DataFrame(y_true, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into a training and a holdout test set (75% vs. 25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative_train_test_split is only deterministic if we call this first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# iterative_train_test_split expects a matrix, whereas CountVectorizer\n",
    "# needs an iterable over strings\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(\n",
    "    df.text.to_frame().values, df_true.values, test_size=0.25\n",
    ")\n",
    "X_train, X_test = X_train[:, 0], X_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test 3 * 2 * 2 = 12 different configurations for preprocessing: tokenization, use of IDF, and use of n-grams. Intermediate results are cached (in a directory `.cache`) to avoid recalculating the time-consuming tokenization part. The code below just sets up the pipeline for each each configuration; the actual processing happens in part 4."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HERE WE NEED TO CHOOSE NGRAMS AND TOKENIZERS\n",
    "# TOKENIZRERS = tokenize_lemmas, tokenize_nouns, tokenize_nounphrases\n",
    "# USE_IDFS = True, False\n",
    "# NGRAMS = (1,1), (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = [tokenize_lemmas, tokenize_nouns, tokenize_nounphrases]\n",
    "use_idfs = [True]\n",
    "ngrams = [(1, 1)]\n",
    "\n",
    "memory = joblib.Memory('.cache', verbose=0)\n",
    "preprocessed_models = {}\n",
    "\n",
    "for tokenizer, ngram, use_idf in itertools.product(tokenizers, ngrams, use_idfs):\n",
    "    pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenizer, ngram_range=ngram)),\n",
    "        ('tfidf', TfidfTransformer(use_idf=use_idf)),\n",
    "    ], memory=memory)\n",
    "    preprocessed_models[(tokenizer, ngram, use_idf)] = pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## PART 4 - Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Multinomial Naïve Bayes\n",
    "\n",
    "We employ 3-fold cross-validation and test different parameters. Classifier chaining is used for multi-label prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=RANDOM_SEED, shuffle=False)\n",
    "parameters = {\n",
    "    'classifier': [MultinomialNB()],\n",
    "    'classifier__alpha': [1, .1, .01, .001, .0001],\n",
    "}\n",
    "\n",
    "classifiers = {}\n",
    "\n",
    "for (tokenizer, ngram, use_idf), pipe in preprocessed_models.items():\n",
    "    print(\"*** Pre-processing using tokenizer {}, IDF {}, n-gram range {}\".format(\n",
    "        tokenizer.__name__, use_idf, ngram   \n",
    "    ))\n",
    "    X_train_preproc = pipe.fit_transform(X_train)\n",
    "    \n",
    "    print(\"*** Predicting for tokenizer {}, IDF {}, n-gram range {}\".format(\n",
    "        tokenizer.__name__, use_idf, ngram\n",
    "    ))\n",
    "    clf = RandomizedSearchCV(\n",
    "        ClassifierChain(require_dense=[False, True]),\n",
    "        parameters,\n",
    "        scoring='accuracy',\n",
    "        n_iter=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        return_train_score=True,\n",
    "        pre_dispatch=2,\n",
    "        cv=cv,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    clf.fit(X_train_preproc, y_train)\n",
    "    \n",
    "    # Persist classifier to disk\n",
    "    location = f\".cache/MNB-{tokenizer.__name__}-{use_idf}-{ngram}.joblib\"\n",
    "    joblib.dump(clf, location)\n",
    "    classifiers[(tokenizer, ngram, use_idf)] = (location, clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the best preprocessing configuration, hyperparameters and score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_input, best_clf_loc, best_score = max(((preproc, loc, score) for preproc, (loc, score) in classifiers.items()), key=lambda x: x[2])\n",
    "best_clf = joblib.load(best_clf_loc)\n",
    "best_input, best_clf.best_params_, best_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = preprocessed_models[best_input]\n",
    "pipe.set_params(vect__vocabulary=pipe.named_steps['vect'].vocabulary_)\n",
    "X_test_preproc = pipe.transform(X_test)\n",
    "y_pred = best_clf.predict(X_test_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate various evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy =\", accuracy_score(y_test, y_pred))\n",
    "print(\"Hamming loss =\", hamming_loss(y_test, y_pred))\n",
    "print(\"Precision =\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 =\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 4.2. Gradient Boosting\n",
    "\n",
    "This follows the same steps as Multinomial NB. Again, we employ 3-fold cross-validation and test different parameters. Classifier chaining is used for multi-label prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, random_state=RANDOM_SEED, shuffle=False)\n",
    "\n",
    "parameters = {\n",
    "        'classifier': [\n",
    "            LGBMClassifier(objective='binary', \n",
    "                           boosting_type='gbdt', \n",
    "                           #early_stopping_rounds=1000,\n",
    "                           verbose=4,\n",
    "                           boost_from_average=False,\n",
    "                           n_jobs=5\n",
    "                        )\n",
    "        ],\n",
    "        'classifier__num_trees': [100, 200, 400, 600],\n",
    "        'classifier__num_leaves': [10, 50, 80, 110, 140, 170, 200],\n",
    "        'classifier__max_depth' : [5, 10, 20, 25],\n",
    "        'classifier__learning_rate': [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'classifier__max_bin': [50, 75, 100, 150, 200, 255],\n",
    "        'classifier__min_data_in_leaf': [5, 10, 20, 40, 60],\n",
    "        'classifier__bagging_fraction': [0.1, 0.2, 0.4, 0.6],\n",
    "        'classifier__bagging_freq': [10, 25, 50],\n",
    "        'classifier__min_child_weight':[1e-3, 1e-2, 1e-1],\n",
    "        'classifier__reg_alpha': [0, 1e-3, 1e-2, 1e-1, 1],\n",
    "        'classifier__reg_lambda': [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Preprocessing for tokenizer tokenize_lemmas, IDF True, n-gram range (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JEykens\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:315: UserWarning: Persisting input arguments took 10.49s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Predicting for tokenizer tokenize_lemmas, IDF True, n-gram range (1, 1)\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "for (tokenizer, ngram, use_idf), pipe in preprocessed_models.items():\n",
    "    print(\"*** Preprocessing for tokenizer {}, IDF {}, n-gram range {}\".format(\n",
    "        tokenizer.__name__, use_idf, ngram\n",
    "    ))\n",
    "    X_train_preproc = pipe.fit_transform(X_train)\n",
    "    \n",
    "    print(\"*** Predicting for tokenizer {}, IDF {}, n-gram range {}\".format(\n",
    "        tokenizer.__name__, use_idf, ngram\n",
    "    ))\n",
    "    clf = RandomizedSearchCV(\n",
    "        ClassifierChain(require_dense=[False, True]),\n",
    "        parameters,\n",
    "        scoring='accuracy',\n",
    "        n_iter=100,\n",
    "        n_jobs=6,\n",
    "        verbose=2,\n",
    "        return_train_score=True,\n",
    "        cv=cv,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    clf.fit(X_train_preproc.astype(\"float32\"), y_train.astype(\"float32\"))\n",
    "\n",
    "    # Persist classifier to disk\n",
    "    location = f\".cache/LightGBM-{tokenizer.__name__}-{use_idf}-{ngram}.joblib\"\n",
    "    joblib.dump(clf, location)\n",
    "    classifiers[(tokenizer, ngram, use_idf)] = (location, clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the best preprocessing configuration, hyperparameters and score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_input, best_clf_loc, best_score = max(((preproc, loc, score) for preproc, (loc, score) in classifiers.items()), key=lambda x: x[2])\n",
    "best_clf = joblib.load(best_clf_loc)\n",
    "best_input, best_clf.best_params_, best_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = preprocessed_models[best_input]\n",
    "pipe.set_params(vect__vocabulary=pipe.named_steps['vect'].vocabulary_)\n",
    "X_test_preproc = pipe.transform(X_test)\n",
    "y_pred = best_clf.predict(X_test_preproc.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate various evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "print(\"Accuracy =\", accuracy_score(y_test, y_pred))\n",
    "print(\"Hamming loss =\", hamming_loss(y_test, y_pred))\n",
    "print(\"Precision =\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 =\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
